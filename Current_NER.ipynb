{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Current_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatreddyt/HW/blob/master/Current_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4s5TFme0Hv3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "TODO: Cleanup text fields \n",
        "add overiview of code at the top\n",
        "2. references\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKemCYHiZ3q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ce0a802e-652e-42d4-e045-72577736cf5d"
      },
      "source": [
        "#Import all the necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda, Layer, Concatenate\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JLVpj2CN2OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff806053-7a45-4002-f76b-3b7ce52b8623"
      },
      "source": [
        "#Mount google drive (uploaded 'ner_dataset.csv' to google drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkgGBFQdVoy-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "cf1858cd-d09c-4188-c6ef-fe192f731e8a"
      },
      "source": [
        "#read the file from drive\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/ner_dataset.csv\", encoding=\"latin1\")\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS    Tag\n",
              "0  Sentence: 1      Thousands  NNS      O\n",
              "1          NaN             of   IN      O\n",
              "2          NaN  demonstrators  NNS      O\n",
              "3          NaN           have  VBP      O\n",
              "4          NaN        marched  VBN      O\n",
              "5          NaN        through   IN      O\n",
              "6          NaN         London  NNP  B-geo\n",
              "7          NaN             to   TO      O\n",
              "8          NaN        protest   VB      O\n",
              "9          NaN            the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2cyrIfYVy3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "40b34206-d6bb-4441-d015-1691b1edb49e"
      },
      "source": [
        "#we can see missing values for sentence, let get statistics on data\n",
        "df.isnull().sum()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqF5HEPJmKCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "a2b90987-f988-417d-b1c0-33098ab09c76"
      },
      "source": [
        "#fill the missing values\n",
        "df = df.fillna(method=\"ffill\")\n",
        "df.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oMz4wa_l8vn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "858a36b3-4c5e-4871-fd76-ac59fb7ae5b3"
      },
      "source": [
        "#desc on data frame\n",
        "df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "      <td>1048575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>47959</td>\n",
              "      <td>35178</td>\n",
              "      <td>42</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Sentence: 22480</td>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>104</td>\n",
              "      <td>52573</td>\n",
              "      <td>145807</td>\n",
              "      <td>887908</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Sentence #     Word      POS      Tag\n",
              "count           1048575  1048575  1048575  1048575\n",
              "unique            47959    35178       42       17\n",
              "top     Sentence: 22480      the       NN        O\n",
              "freq                104    52573   145807   887908"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnxjfI_Yk6D8",
        "colab_type": "text"
      },
      "source": [
        "There are 47959 unique sentences, 35178 unique words and 17 Tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PH1hrxzaa4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "94a1949e-80ec-40f6-df3d-52ef2665ac62"
      },
      "source": [
        "#dropping POS tag, since its not needed\n",
        "df = df.drop(['POS'], axis =1)\n",
        "df.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word Tag\n",
              "0  Sentence: 1      Thousands   O\n",
              "1  Sentence: 1             of   O\n",
              "2  Sentence: 1  demonstrators   O\n",
              "3  Sentence: 1           have   O\n",
              "4  Sentence: 1        marched   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiL12HzicRBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceExtract(object):\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        self.n_sent = 1\n",
        "        self.df = df\n",
        "        self.empty = False\n",
        "        aggreate_function = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.df.groupby(\"Sentence #\").apply(aggreate_function)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_txt(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR4jyjdgcUL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6cb6a3b8-3358-4633-87c3-562ed15a5caf"
      },
      "source": [
        "get_sent = SentenceExtract(df)\n",
        "sent_with_tags = get_sent.get_txt()\n",
        "#sentences with NE tags\n",
        "print(sent_with_tags)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5cEYRQqtfz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f16ea300-2ab1-4aa6-8dcd-8c729caea26a"
      },
      "source": [
        "sentences = get_sent.sentences\n",
        "longest_sentence = max(len(s) for s in sentences)\n",
        "print(longest_sentence, 'words are present in longest sentence')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104 words are present in longest sentence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfes7QYmhFnp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c9b895bb-bbbc-4d8a-c29b-7f922ce9be84"
      },
      "source": [
        "#list of unique tags\n",
        "tags=list(set(df[\"Tag\"].values))\n",
        "print('list of unique tags:',tags)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "list of unique tags: ['O', 'B-art', 'I-geo', 'I-tim', 'I-gpe', 'B-nat', 'B-eve', 'I-eve', 'I-nat', 'I-org', 'I-per', 'B-geo', 'I-art', 'B-gpe', 'B-per', 'B-org', 'B-tim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J845cv4hQ8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d2073d05-6090-4e67-abe8-855589abff94"
      },
      "source": [
        "#list of unique words\n",
        "padding = '_PAD_'\n",
        "words = list(set(df['Word'].values))\n",
        "words.append(padding)\n",
        "print(words[0:10])\n",
        "print('Number of unique words:', len(words))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Dwain', 'Muluzi', 'Mladen', 'panel', '1980', 'Oxen', 'Polska', 'Lance', 'Levy', 'wanting']\n",
            "Number of unique words: 35179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs6uQRJydhZf",
        "colab_type": "text"
      },
      "source": [
        "Prepare sentences to be of equal size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4RSavgc210",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdff4924-5577-4a29-ba92-9839c2397890"
      },
      "source": [
        "word_2_index = {w:i for i,w in enumerate(words)}\n",
        "max_len = 104\n",
        "x_pad = []\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(padding)\n",
        "    x_pad.append(new_seq)\n",
        "\n",
        "x_pad[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_',\n",
              " '_PAD_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hPvhVGgd7eF",
        "colab_type": "text"
      },
      "source": [
        "Pad labels accordingly with O label for padd word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRk67BiYdo2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "56de859f-0ebe-4409-ed09-1bb3d39b3d8c"
      },
      "source": [
        "tag_2_index = {t:i for i,t in enumerate(tags)}\n",
        "y = [[tag_2_index[w[1]] for w in s] for s in sentences]\n",
        "y_pad = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag_2_index[\"O\"])\n",
        "y_pad[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 16,  0,\n",
              "        0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aUrAZ8MX34C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c28a6fd-6ae1-43a3-dd5d-773db870837c"
      },
      "source": [
        "batch_size = 32\n",
        "l = len(x_pad) // batch_size // 25 * 25 * batch_size \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_pad[:l], y_pad[:l], test_size=0.2)\n",
        "Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1)\n",
        "\n",
        "print(*map(len, [X_train, X_test, Y_train, Y_test]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37760 9440 37760 9440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFFYz6oKeUml",
        "colab_type": "text"
      },
      "source": [
        "## Loading gazetteers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eY6wWiKeY8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "f4902e30-3ba8-4293-db65-f7a0da20de66"
      },
      "source": [
        "os.listdir('/content/gdrive/My Drive/gazetteers')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['caprovinces.txt',\n",
              " 'countries.txt',\n",
              " 'nationalities.txt',\n",
              " 'uscities.txt',\n",
              " 'mexstates.txt',\n",
              " 'isocountries.txt',\n",
              " 'usstates.txt',\n",
              " 'usstateabbrev.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj8zp1nCdwP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gazetteers = {}\n",
        "for gz in os.listdir('/content/gdrive/My Drive/gazetteers'):\n",
        "    i = set(open(f'/content/gdrive/My Drive/gazetteers/{gz}', 'r', encoding=\"latin1\").read().strip().split('\\n'))\n",
        "    gazetteers[gz.split('.')[0]] = i"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93QyD823e8eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "bdb72966-6d20-4b54-e6e2-5856db2ec035"
      },
      "source": [
        "list(gazetteers['countries'])[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Antigua and Barbuda',\n",
              " 'Belarus',\n",
              " 'Herzegovina',\n",
              " 'Netherlands Antilles',\n",
              " 'Sierra Leone',\n",
              " 'Aland',\n",
              " 'Ireland',\n",
              " 'Liberia',\n",
              " 'Gabon',\n",
              " 'Trinidad']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iY6bx35fOuq",
        "colab_type": "text"
      },
      "source": [
        "# Ð¡reating model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH8uawTgfZ5b",
        "colab_type": "text"
      },
      "source": [
        "ELMo embedder for word embbeding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XkEoJ-VfVqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "72ecac24-3e55-4101-8cd3-366f7a9bc3b0"
      },
      "source": [
        "elmo_model = hub.load('https://tfhub.dev/google/elmo/2').signatures['tokens']\n",
        "def elmo_emb(x):\n",
        "    return elmo_model(tokens=tf.squeeze(tf.cast(x, tf.string)), \n",
        "                      sequence_len=tf.constant(batch_size*[max_len]))[\"elmo\"]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blMXeScigCBB",
        "colab_type": "text"
      },
      "source": [
        "Function to extract gazzeteer feature for each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B7QC0-Ufy7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#binary feature: 1 if word in gazetteers else 0\n",
        "def GazetteerFeatures(sentences):\n",
        "    result = []\n",
        "    for s in sentences:\n",
        "        data = []\n",
        "        for w in s:\n",
        "            temp = []\n",
        "            for g in gazetteers.values():\n",
        "                temp.append(1 if w in g else 0)\n",
        "\n",
        "            data.append(temp)\n",
        "        result.append(data)\n",
        "                \n",
        "    return np.array(result, dtype=np.float32)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOVSbayVgL5J",
        "colab_type": "text"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btg501uIgIbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "00910dec-c8d1-4c3a-b7d9-4b25deac89b7"
      },
      "source": [
        "    input_txt = Input(shape=(max_len,), dtype=tf.string)\n",
        "    input_gaz  = Input(shape=(max_len, 8), dtype=tf.float32)\n",
        "    elmo_embedding = Lambda(elmo_emb, output_shape=(max_len, 1024))(input_txt)\n",
        "    emb = Concatenate()([elmo_embedding, input_gaz])\n",
        "    x = Bidirectional(LSTM(units=512, return_sequences=True,recurrent_dropout=0.1, dropout=0.1))(emb)\n",
        "    out = TimeDistributed(Dense(17, activation=\"softmax\"))(x)\n",
        "    model = Model([input_txt, input_gaz], out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 104)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 104, 1024)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, 104, 8)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 104, 1032)    0           lambda_2[0][0]                   \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 104, 1024)    6328320     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 104, 17)      17425       bidirectional_2[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 6,345,745\n",
            "Trainable params: 6,345,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEifqSBsVDiV",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdRqPCgkco2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "33fdbd56-bfd6-4312-f1ee-c9a01a0fb6f8"
      },
      "source": [
        "history = model.fit([np.array(X_train), GazetteerFeatures(X_train)], Y_train, validation_split = 0.2,\n",
        "                    batch_size=batch_size, epochs=1, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30400 samples, validate on 7600 samples\n",
            "Epoch 1/1\n",
            "30400/30400 [==============================] - 553s 18ms/step - loss: 0.0558 - accuracy: 0.9851 - val_loss: 0.0256 - val_accuracy: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeVq4DOPzWeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7ef415db-47e8-4a51-a2b2-0b0ea04f0da6"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /tensorflow-1.15.2/python3.6 (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpP1BY-6g7Lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b65fa69b-bf42-4279-fcba-63a14ba2d40a"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "model_predict = model.predict([np.array(X_test), GazetteerFeatures(X_test)], verbose=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9440/9440 [==============================] - 154s 16ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfBk6r1caUWI",
        "colab_type": "text"
      },
      "source": [
        "TODO:DEL\n",
        "### Result and Score section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKCkWQALhFGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "e2badb55-8033-4376-cf04-9efa62b61ce4"
      },
      "source": [
        "idx2tag = {i: w for w, i in tag_2_index.items()}\n",
        "\n",
        "def pred_2_label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(padding, \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test_2_label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(padding, \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "predicted_labels = pred_2_label(model_predict)\n",
        "test_labels = test_2_label(Y_test)\n",
        "print(classification_report(test_labels, predicted_labels))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           precision    recall  f1-score   support\n",
            "\n",
            "      geo       0.01      0.01      0.01      7370\n",
            "      per       0.00      0.01      0.01      3346\n",
            "      tim       0.00      0.03      0.01      4048\n",
            "      org       0.00      0.01      0.00      4011\n",
            "      gpe       0.04      0.15      0.07      3109\n",
            "      eve       0.00      0.00      0.00        76\n",
            "      nat       0.00      0.23      0.00        53\n",
            "      art       0.00      0.06      0.00        71\n",
            "\n",
            "micro avg       0.00      0.03      0.01     22084\n",
            "macro avg       0.01      0.03      0.02     22084\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avDxF3pyhUtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "cbfe89a5-f88c-4493-cb45-084fe66a0c17"
      },
      "source": [
        "i = 375\n",
        "p = model.predict([np.array(X_test[i:i+batch_size]), GazetteerFeatures(X_test[i:i+batch_size])])[0]\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "print(\"=\"*30)\n",
        "for w, true, pred in zip(X_test[i], Y_test[i], p):\n",
        "    if w != padding:\n",
        "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word            Pred : (True)\n",
            "==============================\n",
            "North          :B-art (B-geo)\n",
            "Korea          :B-art (I-geo)\n",
            "says           :B-gpe (O)\n",
            "it             :B-gpe (O)\n",
            "will           :B-gpe (O)\n",
            "delay          :B-gpe (O)\n",
            "a              :B-gpe (O)\n",
            "scheduled      :B-gpe (O)\n",
            "round          :B-gpe (O)\n",
            "of             :B-gpe (O)\n",
            "high           :B-gpe (O)\n",
            "level          :B-gpe (O)\n",
            "inter-Korean   :B-gpe (O)\n",
            "talks          :B-gpe (O)\n",
            ",              :B-gpe (O)\n",
            "because        :B-gpe (O)\n",
            "of             :B-gpe (O)\n",
            "an             :B-gpe (O)\n",
            "upcoming       :B-gpe (O)\n",
            "joint          :B-gpe (O)\n",
            "military       :B-gpe (O)\n",
            "exercise       :I-org (O)\n",
            "between        :B-geo (O)\n",
            "South          :I-art (B-geo)\n",
            "Korea          :B-gpe (I-geo)\n",
            "and            :B-gpe (O)\n",
            "the            :B-gpe (O)\n",
            "United         :I-org (B-geo)\n",
            "States         :I-org (I-geo)\n",
            ".              :I-art (O)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBzw17XFab_l",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "https://www.kaggle.com/abhinavwalia95entity-annotated-corpus/home#ner.csv\n",
        "\n",
        "https://www.kaggle.com/nltkdata/gazetteers\n",
        "\n",
        "https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1603.01354.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1901.08746.pdf\n",
        "\n",
        "https://www.aclweb.org/anthology/W19-5807.pdf\n",
        "\n",
        "https://programminghistorian.org/en/lessons/extracting-keywords\n",
        "\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede\n",
        "\n",
        "https://www.kaggle.com/nltkdata/conll-corpora\n",
        "\n",
        "https://mc.ai/how-to-build-deep-neural-network-for-custom-ner-with-keras/\n",
        "\n",
        "https://medium.com/analytics-vidhya/elmo-embedding-the-entire-intent-of-a-query-530b268c4cd\n",
        "\n",
        "https://www.depends-on-the-definition.com/named-entity-recognition-conditional-random-fields-python/\n",
        "\n",
        "https://towardsdatascience.com/elmo-embeddings-in-keras-with-tensorflow-hub-7eb6f0145440\n",
        "\n",
        "https://confusedcoders.com/data-science/deep-learning/how-to-build-deep-neural-network-for-custom-ner-with-keras"
      ]
    }
  ]
}