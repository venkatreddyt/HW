{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER with gazetteers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatreddyt/HW/blob/master/NER_with_gazetteers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1HINU-tgYXo",
        "colab_type": "text"
      },
      "source": [
        "# NLP & ML Final project: Named Entity Recognition with gazetteers\n",
        "Pavel Nikuiln"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgkVxAka18n",
        "colab_type": "text"
      },
      "source": [
        "## Dataset preparetion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQU3UwoIex_l",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus/home#ner.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKemCYHiZ3q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PH1hrxzaa4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "13fdb8d2-6621-45fb-debe-c7c1855f89b1"
      },
      "source": [
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "data = data.drop(['POS'], axis =1)\n",
        "data = data.fillna(method=\"ffill\")\n",
        "data.head(20)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1b2ec87cbeb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ner_dataset.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'POS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ffill\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ner_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9EqtIk9bCLZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "73243d5b-6b40-43ed-f516-1e8d3c8b47c7"
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags, tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17,\n",
              " ['I-per',\n",
              "  'O',\n",
              "  'B-nat',\n",
              "  'I-nat',\n",
              "  'I-gpe',\n",
              "  'B-art',\n",
              "  'B-per',\n",
              "  'B-org',\n",
              "  'I-art',\n",
              "  'B-tim',\n",
              "  'I-tim',\n",
              "  'I-org',\n",
              "  'I-eve',\n",
              "  'B-geo',\n",
              "  'I-geo',\n",
              "  'B-gpe',\n",
              "  'B-eve'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2tchZ0caeKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_WORD = '--PAD--'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB16FH3KbEBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a559551-fb5e-44a7-87a7-22614503e35d"
      },
      "source": [
        "words = set(list(data['Word'].values))\n",
        "words.add(PAD_WORD)\n",
        "n_words = len(words)\n",
        "print('Number of unique words:', n_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 35179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiL12HzicRBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR4jyjdgcUL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "73b78f10-6978-4db1-d809-e748732a8214"
      },
      "source": [
        "getter = SentenceGetter(data)\n",
        "sent = getter.get_next()\n",
        "print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'), ('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'), ('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'), ('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), ('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'), ('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxCxSEXucWdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad771821-9b6f-4cd1-9942-7f506b519dd7"
      },
      "source": [
        "sentences = getter.sentences\n",
        "print('Number of sentences in corpus:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in corpus: 47959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPpCLRbXcpQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db11c834-0b20-46cb-88e6-f75a199a9908"
      },
      "source": [
        "longest_sen = max(len(sen) for sen in sentences)\n",
        "print(f'Longest sentence has {longest_sen} words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest sentence has 104 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlJ1w-LdczL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "dbbeab5d-6fc4-477b-aa29-be769fc50e6a"
      },
      "source": [
        "%matplotlib inline\n",
        "plt.hist([len(sen) for sen in sentences], bins= 50)\n",
        "plt.title('Sentence length distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs6uQRJydhZf",
        "colab_type": "text"
      },
      "source": [
        "Prepare sentences to be of equal size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4RSavgc210",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "09558875-9f61-404d-a233-fa13b16ef315"
      },
      "source": [
        "words2index = {w:i for i,w in enumerate(words)}\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "\n",
        "max_len = 50\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "padd_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(PAD_WORD)\n",
        "    padd_X.append(new_seq)\n",
        "\n",
        "padd_X[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Israeli',\n",
              " 'officials',\n",
              " 'say',\n",
              " 'Prime',\n",
              " 'Minister',\n",
              " 'Ariel',\n",
              " 'Sharon',\n",
              " 'will',\n",
              " 'undergo',\n",
              " 'a',\n",
              " 'medical',\n",
              " 'procedure',\n",
              " 'Thursday',\n",
              " 'to',\n",
              " 'close',\n",
              " 'a',\n",
              " 'tiny',\n",
              " 'hole',\n",
              " 'in',\n",
              " 'his',\n",
              " 'heart',\n",
              " 'discovered',\n",
              " 'during',\n",
              " 'treatment',\n",
              " 'for',\n",
              " 'a',\n",
              " 'minor',\n",
              " 'stroke',\n",
              " 'suffered',\n",
              " 'last',\n",
              " 'month',\n",
              " '.',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--',\n",
              " '--PAD--']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hPvhVGgd7eF",
        "colab_type": "text"
      },
      "source": [
        "Pad labels accordingly with O label for padd word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRk67BiYdo2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8aec405c-ab07-4c37-c24a-eda978177a9c"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15,  1,  1,  6,  0,  0,  0,  1,  1,  1,  1,  1,  9,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFFYz6oKeUml",
        "colab_type": "text"
      },
      "source": [
        "## Loading gazetteers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2H6plI8erc0",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/nltkdata/gazetteers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eY6wWiKeY8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "7dca9da5-98a8-4ea8-de98-a9f787d87466"
      },
      "source": [
        "os.listdir('./gazetteers')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mexstates.txt',\n",
              " 'caprovinces.txt',\n",
              " 'uscities.txt',\n",
              " 'nationalities.txt',\n",
              " 'countries.txt',\n",
              " 'usstateabbrev.txt',\n",
              " 'usstates.txt',\n",
              " 'isocountries.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj8zp1nCdwP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gazetteers = {}\n",
        "for gazetteer in os.listdir('./gazetteers'):\n",
        "    items = set(open(f'./gazetteers/{gazetteer}', 'r', encoding=\"latin1\").read().strip().split('\\n'))\n",
        "    gazetteers[gazetteer.split('.')[0]] = items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93QyD823e8eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dbdf056-8110-43b3-d252-8290046c1197"
      },
      "source": [
        "list(gazetteers['usstateabbrev'])[:8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NC', 'AR', 'Okla.', 'WV', 'MD', 'WI', 'LA', 'N.Y.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iY6bx35fOuq",
        "colab_type": "text"
      },
      "source": [
        "# Ð¡reating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUeQxbW1e_Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, Input, Sequential\n",
        "from keras.layers.merge import add\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda, Layer, Concatenate\n",
        "from keras import backend as K\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH8uawTgfZ5b",
        "colab_type": "text"
      },
      "source": [
        "ELMo embedder for word embbeding https://arxiv.org/pdf/1802.05365.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XkEoJ-VfVqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9e8733b1-f413-453a-bdb9-d9ba9019c681"
      },
      "source": [
        "elmo_model = hub.load('https://tfhub.dev/google/elmo/2').signatures['tokens']\n",
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(tokens=tf.squeeze(tf.cast(x, tf.string)), \n",
        "                      sequence_len=tf.constant(batch_size*[max_len]))[\"elmo\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blMXeScigCBB",
        "colab_type": "text"
      },
      "source": [
        "Function to extract gazzeteer feature for each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B7QC0-Ufy7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetGazetteersFeatures(sentences):\n",
        "    \"\"\"\n",
        "    Generate feature vectors based on \n",
        "    appearance of each token in gazetteers\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for sentence in sentences:\n",
        "        result = []\n",
        "        for word in sentence:\n",
        "            tmp = []\n",
        "            for gazetteer in gazetteers.values():\n",
        "                tmp.append(1 if word in gazetteer else 0)\n",
        "\n",
        "            result.append(tmp)\n",
        "        data.append(result)\n",
        "                \n",
        "    return np.array(data, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOVSbayVgL5J",
        "colab_type": "text"
      },
      "source": [
        "Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btg501uIgIbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def NERModel(number_of_gazetteers, batch_size=32):\n",
        "    \"\"\"\n",
        "    definition of end-to-end NER model\n",
        "    with additional gazetteer features\n",
        "    \"\"\"\n",
        "    # first input contains sentence splited on tokens\n",
        "    input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "    # second input is gazetteer feature for each token in sentence\n",
        "    input_gazetteer = Input(shape=(max_len, number_of_gazetteers), dtype=tf.float32)\n",
        "\n",
        "    # embed input tokens using ELMo embeddings to extract useful features from sentence\n",
        "    elmo_embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "\n",
        "    # cancatinate ELMo and gazetteer features in one feature vector for each token\n",
        "    embedding = Concatenate()([elmo_embedding, input_gazetteer])\n",
        "\n",
        "    # first BiLSTM\n",
        "    x = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                        recurrent_dropout=0.2, dropout=0.2))(embedding)\n",
        "\n",
        "    # second BiLSTM\n",
        "    x_rnn = Bidirectional(LSTM(units=512, return_sequences=True,\n",
        "                            recurrent_dropout=0.2, dropout=0.2))(x)\n",
        "    # add them together\n",
        "    x = add([x, x_rnn])\n",
        "\n",
        "    # assign lable\n",
        "    out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)\n",
        "\n",
        "    model = Model([input_text, input_gazetteer], out)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exuLLyhGgPvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "d71a3320-6167-4b0e-c91b-0d97e2fdf7f8"
      },
      "source": [
        "batch_size = 32\n",
        "number_of_gazetteers=len(gazetteers.values())\n",
        "\n",
        "model = NERModel(number_of_gazetteers=number_of_gazetteers, batch_size=batch_size)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 50, 1024)     0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            (None, 50, 8)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 50, 1032)     0           lambda_3[0][0]                   \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 50, 1024)     6328320     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 50, 1024)     6295552     bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 50, 1024)     0           bidirectional_5[0][0]            \n",
            "                                                                 bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 50, 17)       17425       add_3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 12,641,297\n",
            "Trainable params: 12,641,297\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VCvvaNkgr4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36b02cc4-cfe6-40c9-9d28-79b5fda0a2b0"
      },
      "source": [
        "l = len(padd_X) // batch_size // 25 * 25 * batch_size \n",
        "X_train, X_test, y_train, y_test = train_test_split(padd_X[:l], y[:l], test_size=0.2)\n",
        "y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
        "\n",
        "print(*map(len, [X_train, X_test, y_train, y_test]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37760 9440 37760 9440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEifqSBsVDiV",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JqHkmqugkm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit([np.array(X_train), GetGazetteersFeatures(X_train)], y_train, validation_split = 0.2,\n",
        "                    batch_size=batch_size, epochs=3, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeVq4DOPzWeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "dac5d469-6151-47e6-ebcb-202754fc5fcd"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.3)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=f930e00be25aeb85839c2cdc0df2493162757f23f43f74eaecf6ed7f8e9c1c9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpP1BY-6g7Lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4bc8fe-10ef-4615-c45d-32c8644d2057"
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "test_pred = model.predict([np.array(X_test), GetGazetteersFeatures(X_test)], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9440/9440 [==============================] - 175s 19ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfBk6r1caUWI",
        "colab_type": "text"
      },
      "source": [
        "## Result and Score section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKCkWQALhFGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e6c80fac-bbb5-42f6-cb4b-ddcf15d8399c"
      },
      "source": [
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(PAD_WORD, \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "\n",
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p].replace(PAD_WORD, \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out\n",
        "    \n",
        "pred_labels = pred2label(test_pred)\n",
        "test_labels = test2label(y_test)\n",
        "print(classification_report(test_labels, pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           precision    recall  f1-score   support\n",
            "\n",
            "      gpe       0.96      0.92      0.94      3105\n",
            "      geo       0.81      0.91      0.86      7305\n",
            "      org       0.73      0.61      0.66      3962\n",
            "      per       0.74      0.80      0.77      3362\n",
            "      tim       0.86      0.85      0.86      4056\n",
            "      nat       0.19      0.66      0.30        29\n",
            "      eve       0.15      0.32      0.20        53\n",
            "      art       0.46      0.15      0.22        74\n",
            "\n",
            "micro avg       0.81      0.83      0.82     21946\n",
            "macro avg       0.81      0.83      0.82     21946\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avDxF3pyhUtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "f05d57ed-d743-4f05-bc3b-cac6364b9d40"
      },
      "source": [
        "i = 378\n",
        "p = model.predict([np.array(X_test[i:i+batch_size]), GetGazetteersFeatures(X_test[i:i+batch_size])])[0]\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15} {:5}: ({})\".format(\"Word\", \"Pred\", \"True\"))\n",
        "print(\"=\"*30)\n",
        "for w, true, pred in zip(X_test[i], y_test[i], p):\n",
        "    if w != PAD_WORD:\n",
        "        print(\"{:15}:{:5} ({})\".format(w, tags[pred], tags[true]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word            Pred : (True)\n",
            "==============================\n",
            "This           :O     (O)\n",
            "year           :O     (O)\n",
            ",              :O     (O)\n",
            "an             :O     (O)\n",
            "unprecedented  :O     (O)\n",
            "26             :O     (O)\n",
            "tropical       :O     (O)\n",
            "storms         :O     (O)\n",
            "have           :O     (O)\n",
            "raged          :O     (O)\n",
            "in             :O     (O)\n",
            "the            :O     (O)\n",
            "Atlantic       :B-geo (B-geo)\n",
            "since          :O     (O)\n",
            "the            :O     (O)\n",
            "season         :O     (B-tim)\n",
            "began          :O     (O)\n",
            "on             :O     (O)\n",
            "June           :B-tim (B-tim)\n",
            "first          :I-tim (I-tim)\n",
            ".              :O     (O)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBzw17XFab_l",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1603.01354.pdf\n",
        "\n",
        "https://arxiv.org/pdf/1901.08746.pdf\n",
        "\n",
        "https://www.aclweb.org/anthology/W19-5807.pdf\n",
        "\n",
        "https://programminghistorian.org/en/lessons/extracting-keywords\n",
        "\n",
        "https://towardsdatascience.com/named-entity-recognition-ner-meeting-industrys-requirement-by-applying-state-of-the-art-deep-698d2b3b4ede\n",
        "\n",
        "https://www.kaggle.com/nltkdata/conll-corpora\n",
        "\n",
        "https://mc.ai/how-to-build-deep-neural-network-for-custom-ner-with-keras/\n",
        "\n",
        "https://medium.com/analytics-vidhya/elmo-embedding-the-entire-intent-of-a-query-530b268c4cd\n",
        "\n",
        "https://www.depends-on-the-definition.com/named-entity-recognition-conditional-random-fields-python/\n",
        "\n",
        "https://towardsdatascience.com/elmo-embeddings-in-keras-with-tensorflow-hub-7eb6f0145440\n",
        "\n",
        "https://confusedcoders.com/data-science/deep-learning/how-to-build-deep-neural-network-for-custom-ner-with-keras"
      ]
    }
  ]
}